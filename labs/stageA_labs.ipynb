{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [{'entity': 'I-ORG', 'score': 0.64403105, 'index': 4, 'word': 'Ham', 'start': 7, 'end': 10}, {'entity': 'I-ORG', 'score': 0.8081638, 'index': 5, 'word': '##oy', 'start': 10, 'end': 12}, {'entity': 'I-ORG', 'score': 0.9412854, 'index': 6, 'word': '##e', 'start': 12, 'end': 13}, {'entity': 'I-PER', 'score': 0.99075085, 'index': 12, 'word': 'N', 'start': 40, 'end': 41}, {'entity': 'I-PER', 'score': 0.98543763, 'index': 13, 'word': '##nae', 'start': 41, 'end': 44}, {'entity': 'I-PER', 'score': 0.9662203, 'index': 14, 'word': '##me', 'start': 44, 'end': 46}, {'entity': 'I-PER', 'score': 0.88381165, 'index': 15, 'word': '##ka', 'start': 46, 'end': 48}]\n"
     ]
    }
   ],
   "source": [
    "result = nlp(\"I am a Hamoye instructor and my name is Nnaemeka\")\n",
    "print(\"result:\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.644031</td>\n",
       "      <td>4</td>\n",
       "      <td>Ham</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.808164</td>\n",
       "      <td>5</td>\n",
       "      <td>##oy</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.941285</td>\n",
       "      <td>6</td>\n",
       "      <td>##e</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.990751</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.985438</td>\n",
       "      <td>13</td>\n",
       "      <td>##nae</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.966220</td>\n",
       "      <td>14</td>\n",
       "      <td>##me</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.883812</td>\n",
       "      <td>15</td>\n",
       "      <td>##ka</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity     score  index   word  start  end\n",
       "0  I-ORG  0.644031      4    Ham      7   10\n",
       "1  I-ORG  0.808164      5   ##oy     10   12\n",
       "2  I-ORG  0.941285      6    ##e     12   13\n",
       "3  I-PER  0.990751     12      N     40   41\n",
       "4  I-PER  0.985438     13  ##nae     41   44\n",
       "5  I-PER  0.966220     14   ##me     44   46\n",
       "6  I-PER  0.883812     15   ##ka     46   48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.971832</td>\n",
       "      <td>3</td>\n",
       "      <td>Cold</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.963390</td>\n",
       "      <td>4</td>\n",
       "      <td>##stone</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.954457</td>\n",
       "      <td>5</td>\n",
       "      <td>Ice</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>6</td>\n",
       "      <td>##cre</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>7</td>\n",
       "      <td>##am</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.901036</td>\n",
       "      <td>9</td>\n",
       "      <td>Dom</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.874147</td>\n",
       "      <td>10</td>\n",
       "      <td>##ino</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.958965</td>\n",
       "      <td>11</td>\n",
       "      <td>'</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.958817</td>\n",
       "      <td>12</td>\n",
       "      <td>s</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.962574</td>\n",
       "      <td>13</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity     score  index     word  start  end\n",
       "0  I-ORG  0.971832      3     Cold      7   11\n",
       "1  I-ORG  0.963390      4  ##stone     11   16\n",
       "2  I-ORG  0.954457      5      Ice     17   20\n",
       "3  I-ORG  0.913391      6    ##cre     20   23\n",
       "4  I-ORG  0.967593      7     ##am     23   25\n",
       "5  I-ORG  0.901036      9      Dom     30   33\n",
       "6  I-ORG  0.874147     10    ##ino     33   36\n",
       "7  I-ORG  0.958965     11        '     36   37\n",
       "8  I-ORG  0.958817     12        s     37   38\n",
       "9  I-ORG  0.962574     13    Pizza     39   44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = nlp(\"I love Coldstone Icecream and Domino's Pizza\")\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question and Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "qna = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question.\n",
    "An example of a question answering dataset is the SQuAD dataset, which is entirely based on that task. \n",
    "If you would like to fine-tune a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qna(question=\"What is a good example of a question answering dataset?\",context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5152311325073242, 'start': 147, 'end': 160, 'answer': 'SQuAD dataset'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
